{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j30cGm1Cyh0s"
   },
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9328,
     "status": "ok",
     "timestamp": 1579630411605,
     "user": {
      "displayName": "Léo Andéol",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCZ9lXKogam3N-Zp1ZulY_dPre1MZo_DYuijwWz=s64",
      "userId": "15347828844155644240"
     },
     "user_tz": -60
    },
    "id": "0DzX-9DcgpQ_",
    "outputId": "4e1ecdaa-9285-4872-868c-232d2c4bb107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-video in /home/leo/.local/lib/python3.7/site-packages (1.1.11)\n",
      "Requirement already satisfied: opencv-python in /home/leo/.local/lib/python3.7/site-packages (4.1.1.26)\n",
      "Requirement already satisfied: scipy in /home/leo/.local/lib/python3.7/site-packages (from scikit-video) (1.2.0)\n",
      "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from scikit-video) (5.4.1)\n",
      "Requirement already satisfied: numpy in /home/leo/.local/lib/python3.7/site-packages (from scikit-video) (1.18.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-video opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_jsWDgVyh0z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "# due to GPU issue on my computer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6HMdaHGyh1B"
   },
   "source": [
    "# MiniProject on Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7z4XxDgyh1D"
   },
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wP3alIHvyh1F"
   },
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJL_oNevyh1J"
   },
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G_xRUV_dyh1L"
   },
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aW9S9QHPyh1N"
   },
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CN6Zc0O6yh1P"
   },
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kft0EqhVyh1T"
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6xgUv45yh1f"
   },
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5JyJnchyh1i"
   },
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l3zfSFexyh1k"
   },
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lc8I-5iOyh1m"
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9JBe021yh1s"
   },
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Des_NiWqyh1u"
   },
   "source": [
    "During training, the function act uses an hyperparameter $\\epsilon$ between 0 and 1 to balance choosing an action by using the policy learned, or randomly. It is used to balance exploitation of the known policy, and exploration of other policies in order to avoid local optimas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bNKRIDbRyh1w"
   },
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-fNWWcOmyh1z"
   },
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmL8ovtIyh11"
   },
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OY3RaUq7yh12"
   },
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sD4HCnL2yh15"
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:, -2:] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:,-2:] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YlCusmmyh1_"
   },
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5FF4GhOyh2B"
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=51\n",
    "epochs_test=11\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rrc8ZJH2yh2J"
   },
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qrKpi3iyyh2L"
   },
   "source": [
    "the matrix position incorporates the information on where the agent is (=1), where it can go (=0), and can't (-1). the other matrix board is for rewards for each coordinates : +0.5, 0 , or -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iqN-9T6Pyh2M"
   },
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4Rm94_Ryh2P"
   },
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opN-xL_Wyh2Q"
   },
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        return np.random.randint(0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XrIrE2moyh2V"
   },
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-gQOMZ_yh2W"
   },
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        state = env.reset()\n",
    "        # This assumes that the games will end\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            #loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6682,
     "status": "ok",
     "timestamp": 1579643258053,
     "user": {
      "displayName": "Léo Andéol",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCZ9lXKogam3N-Zp1ZulY_dPre1MZo_DYuijwWz=s64",
      "userId": "15347828844155644240"
     },
     "user_tz": -60
    },
    "id": "0C9TtXggyh2c",
    "outputId": "5a6bcd92-b55c-4739-82e8-3fd513962901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 5.5/6.0. Average score (-0.5)\n",
      "Win/lose count 8.5/16.0. Average score (-4.0)\n",
      "Win/lose count 10.5/16.0. Average score (-4.5)\n",
      "Win/lose count 7.0/16.0. Average score (-5.625)\n",
      "Win/lose count 13.5/20.0. Average score (-5.8)\n",
      "Win/lose count 8.5/12.0. Average score (-5.416666666666667)\n",
      "Win/lose count 9.5/21.0. Average score (-6.285714285714286)\n",
      "Win/lose count 5.0/15.0. Average score (-6.75)\n",
      "Win/lose count 6.5/9.0. Average score (-6.277777777777778)\n",
      "Win/lose count 9.0/12.0. Average score (-5.95)\n",
      "Win/lose count 8.0/15.0. Average score (-6.045454545454546)\n",
      "Final score: -6.045454545454546\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAGCZtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1NSByMjkxNyAwYTg0ZDk4IC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxOCAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9NiBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAALbZYiEADf//vaH+BTZWBP+Wb/9DX/cj9uPrP1xYyEE31qvIejAGS+1H+b/rFFs6Z6UB/fgCJQAc24ZwpHZJ3jjhJSYReqPgUuAn34FNJkRcBCyyf4lLZI51u/uRzDYWmZ6csuhBdNETDXcCd04T88BFrFrsVK2kpKXwfIKeSaEV5pJAtFS8K0jqAX+wztypBWP6sM94ww41vaqj3+rmRHTjDUZVRkg/JNqsh3/s0yArrWPb51MRQRv0Rp+Md/6NbA+6fo4RFdGN1lu84ta1Jm7vxLI/CeFNcQFjBgCRRP7YjO4PfHNgKWPk9UdnPDg370794zm3MpO0ToqQhDOnbWmYPqXl2OkYQOo3EEnd8G4jRNiFoXpk3U+LhT1WxDHQhRGZ9ygkT8iUJ9P3j9IfCWSzFVutxBXyNmON75SKPWBb2IdpANFtvkeaLY0eSUslZV6b2AGZ/RpfIiAbSQCR3K6K0AtC+tNeddfbFpU+4puGQA8IYHnwVmzhSC35ouHV0HEgGfi3hOCG3oK8+BABVlZHabkaudPjpqfGQMdrUo7c2tC3QE5CgqhQdFLrIpDn0AmDmrg2pFrxfiA4AAUwfnxZ5M3jyKIzhkdVWMAw9zIiT//jYhdwmewsjg0x9DB2av3BYdw7kt7Am6H6OEfJPN11tC0JxV+VDBmVfDWyEUPgyWNtT0qhN/3R/DjVifjRxwD/aFwAAkP94GOR8qh2Ag3QQqjUh4OZIMdpsm3wYIR5TaAJfoH3kflQ656Q7qTq6O3OVp8vIIN9SdnLLsOckuIi6N9TplgXGWye6nQuCHOjbiz+grPLgn6wC2WBEqY8HleDlTwUq5C/qEMqpDy/xYJmoDrEyhhZ0bwoi0mZ2W2QB5SHHBZHnZjbxAYw2TrSrebiXlqrPliw+a4MO6DjFXMvaxmWnNoWpMunBFdhk+ztKJEAOJb+g/lyr8Al9Tc9ZGu+Skri0AmIRoABUUAAAAWQZoibEN//qeEAYLx0+0UfFmKEcdXcAAAAA8BnkF5Cv8BLpQBklv9bQ8AAAAlQZpGPCGTKYQ3//6nhADn+wf6T3hRfApr6g34FKlo/ApnYGj9gQAAABRBnmRqU8L/AIrQJIrLtHTtYrYhsQAAABABnoN0Qr8AvqdSeV+SmzDxAAAADwGehWpCvwCC7EeS5nyTEwAAABlBmodJqEFomUwIb//+p4QAo/xp0FazKa0HAAAAGkGaqEnhClJlMCHf/qmWAFC+UkDh8eoFgFfAAAAAGUGay0nhDomUwId//qmWAHdTISbhwUfNGBAAAAARQZ7pRRE8K/8Aw7tP+jkiqQ8AAAAQAZ8KakK/AMO6p5MD17bUgAAAABxBmw5JqEFomUwId//+qZYAehMhJraX9p3m7XdAAAAAEUGfLEURLCv/AMizc1x73qEbAAAADwGfTWpCvwDIktKkUCVSDwAAABpBm1FJqEFsmUwId//+qZYATn48/fsg3FP/MQAAAA9Bn29FFSwr/wB8Qf800+AAAAAOAZ+QakK/AHxsAPju/p8AAAAdQZuVSahBbJlMCHf//qmWAEwXiEdTT6Mfpb5uWMcAAAARQZ+zRRUsL/8AWugRWlBzRjwAAAAPAZ/SdEK/AFHjGLgPy2qgAAAAEAGf1GpCvwB8OcNe80rNv8EAAAAeQZvZSahBbJlMCG///qeEAOwDw4saof746eKylsJtAAAAE0Gf90UVLC//AI7n7Na+DHWyumEAAAAQAZ4WdEK/AHl4szyvyU2dSQAAABABnhhqQr8Aw7tRyv7cPpBAAAAAGkGaGkmoQWyZTAh3//6plgB6B0/KaMfrSUHBAAAAMEGaPknhClJlMCHf/qmWAjEoV3xCDb/8JUxKYv/8JO6vi//xhPSNIUqLyqBw/qWXgAAAABBBnlxFNEwv/wFlVZ5Eqdf5AAAADwGee3RCvwE3EAdCcl3GwQAAABABnn1qQr8B3x98tf22fL/AAAAAEkGaYkmoQWiZTAhv//6nhAABJwAAAAxBnoBFESwv/wAAsoEAAAAQAZ6/dEK/Ad9pWMJYchB3EAAAABEBnqFqQr8B3hSYPP3/l/qG9QAAABlBmqVJqEFsmUwIb//+p4QEMEFm1ZQciPlpAAAAEkGew0UVLCv/Ad6y/VHrgmWHgQAAAA4BnuRqQr8B32em/WolxwAAAB1BmudJqEFsmUwUTDf//qeEAZHx0+0UYWzFCOOraQAAAA8BnwZqQr8BNpW6UaQ8SfcAAAAZQZsISeEKUmUwIb/+p4QA7XsH+E4LdCRgQAAAABlBmytJ4Q6JlMCG//6nhACbfHT6jjQkOFbAAAAAD0GfSUURPCv/AHxB/zTT4QAAAA0Bn2pqQr8AfGwKBpVmAAAAG0GbbUmoQWiZTBTw3/6nhACWrNIW3a8dPtW2oAAAABABn4xqQr8AeZnzG6HJBxf5AAAAHEGbj0nhClJlMFLDP/6eEAOZ65G7HDS3199tpOEAAAAQAZ+uakK/AMO6p5MD17bUgQAAABlBm7BJ4Q6JlMCG//6nhADxg8KdZ0+62umAAAAAGUGb0UnhDyZTAhv//qeEAPcDwp1nT7ra44AAAAAwQZvzSeEPJlMFETw3//6nhASuSLj4hAD/+EqILMX/+EmI/F//r/4+n+BNf0a5cxWVAAAAEAGeEmpCvwHsH3y1/bZ8vmAAAAARQZoXSeEPJlMCG//+p4QAAScAAAAMQZ41RRE8L/8AALKBAAAAEAGeVHRCvwHsJA19W0HwgYAAAAAQAZ5WakK/AevtDoRY5MMnYQAAABxBmllJqEFomUwU8M/+nhAQvxHPze7Frb3VzlbBAAAAEAGeeGpCvwHrsv1R8x+LYMAAAAAZQZp6SeEKUmUwIb/+p4QBkfHT6XxQkMKLgQAAABlBmptJ4Q6JlMCG//6nhADy+wf4Tgt0JF3AAAAAF0GavknhDyZTAhv//qeEAPGnhrPs+aLvAAAAEkGe3EURPCv/AMi7UCEjH7drQQAAAA4Bnv1qQr8AyLtV0/UrWgAAABpBmv9JqEFomUwId//+qZYAygmG6LdzH4Ci4AAAABpBmwNJ4QpSZTAh3/6plgDL+PP5HH4oJx6toQAAABVBnyFFNEwv/wFbSS/M24Yd/G9w8LgAAAAQAZ9AdEK/Ad9pWLY2IKJccQAAAA8Bn0JqQr8B0bYxV4An8jMAAAAZQZtHSahBaJlMCHf//qmWAMojuwm99XiY/wAAABVBn2VFESwv/wDiJ6xgfosWwXKQM3EAAAAQAZ+EdEK/ASb1EifFmKNWUQAAABABn4ZqQr8BNtiPJcz5JOuBAAAAHEGbi0moQWyZTAh3//6plgJVZ0QLM+e70Y9MqtgAAAAQQZ+pRRUsL/8BcE6W8EBb0AAAAA8Bn8h0Qr8BNrQgMkuUl4EAAAAQAZ/KakK/AeweDyYGv2WpgAAAABJBm89JqEFsmUwIb//+p4QAAScAAAAMQZ/tRRUsL/8AALKBAAAAEgGeDHRCvwHsJDVAOaJlyDxQQQAAABABng5qQr8B6+0OhFjkwydhAAAAG0GaEEmoQWyZTAh3//6plgJgyAKBACXIfBCLyAAAABtBmjRJ4QpSZTAh3/6plgIx2Y/M+CWcoNwThqQAAAAQQZ5SRTRML/8BZRGtusFxwQAAABABnnF0Qr8B3n8Bkln9Za2AAAAADwGec2pCvwHR7Q6Fo2nTQAAAABJBmnhJqEFomUwIb//+p4QAAScAAAAMQZ6WRREsL/8AALKAAAAADwGetXRCvwErVI4jsuypNwAAABABnrdqQr8B0e0Of5lu/W9BAAAAHUGaukmoQWyZTBRMO//+qZYAxHjz+RxqdQg3BuuOAAAAEAGe2WpCvwEuk+c60MLw9MEAAAAZQZrdSeEKUmUwId/+qZYAd0dPymjH60lDwAAAABJBnvtFNEwr/wDDurewsF+WkYEAAAAOAZ8cakK/AMO6+POCBI0AAAATQZsBSahBaJlMCHf//qmWAACVgAAAABNBnz9FESwv/wCO+gilI6ZyxaBuAAAAEAGfXnRCvwDIvJvK2UPR78EAAAAQAZ9AakK/AMiCxr3mlZtSQAAAABpBm0RJqEFsmUwId//+qZYAegdPymjH60lBwQAAAA9Bn2JFFSwr/wDIkaBrUkAAAAANAZ+DakK/AMjYkW9akwAAABNBm4hJqEFsmUwId//+qZYAAJWBAAAAE0GfpkUVLC//AOdu3TOK6nbbjW0AAAAPAZ/FdEK/AT/MncGyXjHrAAAADwGfx2pCvwE/bbpRpDxJ6wAAABxBm8xJqEFsmUwIb//+p4QA8vsH+cp14Ua3Mdd0AAAAEEGf6kUVLC//AJLn7NwQIPEAAAAPAZ4JdEK/AMik1PVnfVFAAAAADwGeC2pCvwDIktKkUCVSDgAAABJBmhBJqEFsmUwIb//+p4QAAScAAAAMQZ4uRRUsL/8AALKBAAAAEAGeTXRCvwB7FDd07Lsqu4EAAAAQAZ5PakK/AHsUN7FaPt1+QAAAABpBmlFJqEFsmUwIb//+p4QAm3x0+o40JDhWwAAAABlBmnRJ4QpSZTAhv/6nhABk/YP8JwW6EnHBAAAAD0GekkU0TCv/AFHbcCTwQAAAAA0BnrNqQr8AUflYeKeCAAAAHUGatkmoQWiZTBTw3/6nhAA/vsH82l3MrNU1ud7VAAAAEAGe1WpCvwA0xHbnWhheZMAAAAAZQZrYSeEKUmUwUsN//qeEAD9p4cze6nxdjwAAABABnvdqQr8ANM6p5MD17kWBAAAAGUGa+UnhDomUwIb//qeEAGRpE/1W+Y/EQcAAAAAcQZsbSeEPJlMFFTw3//6nhABk/YP88oDUg0RiwQAAABABnzpqQr8AVClG80xVtKLAAAAAF0GbPknhDyZTAhv//qeEAEG+OmbAoK//AAAAEkGfXEURPCv/ADYEeiAUwDkuYQAAAA4Bn31qQr8ANhYlXU6cLwAAABpBm39JqEFomUwId//+qZYAID8efv2QbioV4AAAABZBm4NJ4QpSZTAh3/6plgANlBZXJurxAAAAFEGfoUU0TC//ABjdwu/2OpZch/8WAAAADwGfwHRCvwAhrsoUm2SriwAAAA8Bn8JqQr8AIbs8tw2bVCMAAAATQZvHSahBaJlMCHf//qmWAACVgQAAABBBn+VFESwv/wAZKJbN+j+3AAAAEAGeBHRCvwAhrq0ZJb/XV4EAAAAPAZ4GakK/ACG7EeTA9e6vAAAAHEGaC0moQWyZTAhv//6nhABBR8zU2bcZvdT4uvQAAAAVQZ4pRRUsL/8AJ9QbNvfrjYic+DcQAAAAEAGeSHRCvwAzkmhE+LMUd5kAAAAQAZ5KakK/ADYOqeS5nyUrgAAAABpBmk5JqEFsmUwIb//+p4QAQb46fUcaEhxlQAAAAA9BnmxFFSwr/wA2BLWai6EAAAANAZ6NakK/ADYWLDxUXQAAABtBmpJJqEFsmUwIb//+p4QAP2u4rMnfsH+hJeEAAAAQQZ6wRRUsL/8AJrn7nCym+AAAAA4Bns90Qr8AI7uO884uFwAAABABntFqQr8ANgCxr3mlZwvBAAAAGkGa00moQWyZTAhv//6nhABkaRP9VvmPxEHAAAAAGUGa9EnhClJlMCG//qeEAGbdWkEIn+W28IAAAAAbQZsYSeEOiZTAhv/+p4QAa91sYEIn8ml4CB25AAAAEEGfNkURPC//AD+JqzuhpxwAAAAPAZ9VdEK/AFZtHeecWumBAAAAEAGfV2pCvwBYrCPJcz5J0YEAAAAaQZtZSahBaJlMCHf//qmWAFS+QZoA9JfX/TAAAAAZQZt8SeEKUmUwId/+qZYAVvSyuM0v7YBRQQAAABJBn5pFNEwr/wDSw0u8xg7Va9IAAAAPAZ+7akK/ANKTJNTQOKXhAAAAGkGboEmoQWiZTAhv//6nhAEF+OmY4bjzeFn/AAAAEEGf3kURLC//AJ8xtuHs8bAAAAAQAZ/9dEK/ANfZV3IbKlH/MAAAAA8Bn/9qQr8A0tiwLr+/fSEAAAAdQZviSahBbJlMFEw3//6nhAGditmJ/qtu6n7MEHAAAAAQAZ4BakK/AT+yITcZ9emqSQAAABxBmgRJ4QpSZTBSw3/+p4QELjNU1m1+uif4TjugAAAAEAGeI2pCvwHrhe9ImNZlg4EAAAAcQZomSeEOiZTBRMO//qmWAjHZj8z4JZyg3BOGpQAAABABnkVqQr8B3rL9UfMfi2NBAAAAG0GaSknhDyZTAhv//qeEA5D8TXGp5fon+E4+YQAAABVBnmhFETwv/wFRoEU8GFQR+7V5/ZQAAAAQAZ6HdEK/AS51aMkt/raHgAAAABABnolqQr8BxmeBdf24fMPBAAAAG0GajEmoQWiZTBTw7/6plgHV4hBs/v+pQEoScAAAABABnqtqQr8B0g8GuPFW0bBgAAAAG0GasEnhClJlMCG//qeEBC4zNTZtePeOngEf4QAAABBBns5FNEwv/wFlEa26wXHBAAAADwGe7XRCvwHfRDMhoGZxvQAAAA8Bnu9qQr8B32giSv76bMAAAAAbQZrxSahBaJlMCHf//qmWAjHaqGJ/BEw6PvlpAAAAEkGbFUnhClJlMCHf/qmWAACVgQAAAAxBnzNFNEwv/wAAsoAAAAAQAZ9SdEK/ATNUjvwAfbpowAAAAA8Bn1RqQr8BP1GiC1Hl0fMAAAAcQZtZSahBaJlMCG///qeEA9g8TXGp4jon+E49IAAAABVBn3dFESwv/wFwPv0zi2uj8eZa15EAAAAQAZ+WdEK/AexCtV4DV2WpgQAAAA8Bn5hqQr8B67HVGlEpYtIAAAAaQZuaSahBbJlMCHf//qmWAgHZj8fjDo++XEEAAAAbQZu+SeEKUmUwIb/+p4QBgvHT7V68DwborBFwAAAAFUGf3EU0TC//ANyI44Ayhp9Fldob2QAAAA8Bn/t0Qr8BLnZQpNslUWUAAAAQAZ/9akK/AMi6p5LmfJK4gAAAABlBm+BJqEFomUwU8N/+p4QBf7aWv9E/xcO6AAAAEAGeH2pCvwEu2iE3GfXpqtkAAAARQZoESeEKUmUwIb/+p4QAAScAAAAMQZ4iRTRML/8AALKBAAAAEAGeQXRCvwHSaVi8/gcjXkAAAAAPAZ5DakK/ATZ5ogtR5dH/AAAAG0GaSEmoQWiZTAhf//6MsA+Xx0zi0sd6u+gxqQAAABVBnmZFESwv/wFlVpjA/RYtceUa2DEAAAAQAZ6FdEK/AcaMyI7FmKNOOQAAABABnodqQr8B3x4PJcz4VJeAAAAAGkGaiUuoQhBbJEYIKAfyAf2HgCFf/jhAABFwAAAMCG1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAB+QAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAsydHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAB+QAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAEQAAABEAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAfkAAABAAAAQAAAAAKqm1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAMgAAAZQAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAAClVtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAoVc3RibAAAAJVzdHNkAAAAAAAAAAEAAACFYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAEQARAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAAC9hdmNDAfQADf/hABdn9AANkZsoIhHQgAAAAwCAAAAZB4oUywEABWjr48RIAAAAGHN0dHMAAAAAAAAAAQAAAMoAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAXgY3R0cwAAAAAAAAC6AAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAgAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAgAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAADKAAAAAQAAAzxzdHN6AAAAAAAAAAAAAADKAAAFkAAAABoAAAATAAAAKQAAABgAAAAUAAAAEwAAAB0AAAAeAAAAHQAAABUAAAAUAAAAIAAAABUAAAATAAAAHgAAABMAAAASAAAAIQAAABUAAAATAAAAFAAAACIAAAAXAAAAFAAAABQAAAAeAAAANAAAABQAAAATAAAAFAAAABYAAAAQAAAAFAAAABUAAAAdAAAAFgAAABIAAAAhAAAAEwAAAB0AAAAdAAAAEwAAABEAAAAfAAAAFAAAACAAAAAUAAAAHQAAAB0AAAA0AAAAFAAAABUAAAAQAAAAFAAAABQAAAAgAAAAFAAAAB0AAAAdAAAAGwAAABYAAAASAAAAHgAAAB4AAAAZAAAAFAAAABMAAAAdAAAAGQAAABQAAAAUAAAAIAAAABQAAAATAAAAFAAAABYAAAAQAAAAFgAAABQAAAAfAAAAHwAAABQAAAAUAAAAEwAAABYAAAAQAAAAEwAAABQAAAAhAAAAFAAAAB0AAAAWAAAAEgAAABcAAAAXAAAAFAAAABQAAAAeAAAAEwAAABEAAAAXAAAAFwAAABMAAAATAAAAIAAAABQAAAATAAAAEwAAABYAAAAQAAAAFAAAABQAAAAeAAAAHQAAABMAAAARAAAAIQAAABQAAAAdAAAAFAAAAB0AAAAgAAAAFAAAABsAAAAWAAAAEgAAAB4AAAAaAAAAGAAAABMAAAATAAAAFwAAABQAAAAUAAAAEwAAACAAAAAZAAAAFAAAABQAAAAeAAAAEwAAABEAAAAfAAAAFAAAABIAAAAUAAAAHgAAAB0AAAAfAAAAFAAAABMAAAAUAAAAHgAAAB0AAAAWAAAAEwAAAB4AAAAUAAAAFAAAABMAAAAhAAAAFAAAACAAAAAUAAAAIAAAABQAAAAfAAAAGQAAABQAAAAUAAAAHwAAABQAAAAfAAAAFAAAABMAAAATAAAAHwAAABYAAAAQAAAAFAAAABMAAAAgAAAAGQAAABQAAAATAAAAHgAAAB8AAAAZAAAAEwAAABQAAAAdAAAAFAAAABUAAAAQAAAAFAAAABMAAAAfAAAAGQAAABQAAAAUAAAAHgAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1OC4yMC4xMDA=\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rypa4msqyh2h"
   },
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6t1I7C1yh2k"
   },
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QmLC1O1Hyh2n"
   },
   "source": [
    "#### Answer \n",
    "Starting from the definition introduced at the beginning of this homework\n",
    "\\begin{align} Q^\\pi(s,a) &= \\mathbf{E}\\left[\\sum_t \\gamma^{t}r(s_t,a_t)|s_0=s,a_0=a\\right] \\\\\n",
    "&= r(s, a) + \\gamma \\mathbf{E}\\left[\\sum\\limits_{t \\ge 1} \\gamma^{t - 1} r(s_t,a_t)|s_0=s,a_0=a\\right] \\\\\n",
    "&= r(s, a) + \\gamma \\sum\\limits_{s'} {P}(s_1 = s' | s_0 = s) \\mathbf{E}\\left[\\sum\\limits_{t \\ge 1} \\gamma^{t - 1} r(s_t,a_t)|s_1=s',a_1=a'=\\pi(s)\\right] \\\\\n",
    "&= r(s, a) + \\gamma \\sum\\limits_{s'} {P}(s_1 = s' | s_0 = s) Q^\\pi(s', a') \\\\\n",
    "&= \\mathbf{E}_{(s',a')\\sim p(.|s,a)}\\left[r(s,a)+\\gamma Q^{\\pi}(s',a')\\right] \\end{align}\n",
    "We obtain the recursive formulation of the Q value based on the optimal policy $\\pi^{*}$, and we can proceed to compute the general Q value as follows, by propagating the max :\n",
    "\\begin{align} Q^{*}(s, a) &= \\max\\limits_{\\pi}  Q^{\\pi}(s, a) \\\\ \n",
    "&= \\max\\limits_{\\pi} \\left[ r(a, s) + \\gamma \\sum_{s'} {P}(s_1 = s' | s_0 = s) Q^{\\pi^*}(s', \\pi(s)) \\right] \\\\ &= r(a, s) + \\gamma \\sum\\limits_{s'} {P}(s_1 = s' | s_0 = s) \\max\\limits_{\\pi} Q^{\\pi^*}(s', \\pi(s)) \\\\ &= r(a, s) + \\gamma \\sum_{s'} {P}(s_1 = s' | s_0 = s) \\max\\limits_{a'} Q^{*}(s', a') \\\\ &= \\mathbf{E}_{s'\\sim \\pi^(.|s,a)}\\left[r(s,a)+\\gamma\\max\\limits_{a'}Q^{*}(s',a')\\right] \\end{align}\n",
    "In order to learn this function, we must have a loss function. From the previous formulation we can get\n",
    "\\begin{align}\n",
    "    & \\mathbf{E}_{s'\\sim \\pi^(.|s,a)}\\left[r(s,a)+\\gamma\\max\\limits_{a'}Q^{*}(s',a')\\right]-Q^{*}(s,a) &=0\\\\\n",
    "    \\implies & \\mathbf{E}_{s'\\sim \\pi^(.|s,a)}\\left[r(s,a)+\\gamma\\max\\limits_{a'}Q^{*}(s',a')-Q^{*}(s,a)\\right] &=0\n",
    "\\end{align}\n",
    "And thus estimating it using the $L_2$ distance as loss function to minimize is a plausible objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sN4mdK4Gyh2n"
   },
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2ObmWp1yh2p"
   },
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        self.memory.append(m)\n",
    "        if len(self.memory)>self.max_memory:\n",
    "          self.memory = self.memory[1:]\n",
    "\n",
    "    def random_access(self):\n",
    "        return np.random.permutation(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TPevv-pYyh2v"
   },
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvoOiDcQyh2x"
   },
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jn7dILVmyh22"
   },
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1G7kl54yh24"
   },
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        #print(\"learned_act\",s.shape)\n",
    "        s2 = self.model.predict(s[np.newaxis,:,:,:])\n",
    "        #print(\"learned_act2\",s.shape)\n",
    "        #print(s2)\n",
    "        a = np.argmax(s2,axis=1)[0]\n",
    "        #print(\"learned_act3\",a)\n",
    "        return a\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "\n",
    "        batch = self.memory.random_access()[:self.batch_size]\n",
    "\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            if len(batch)<=i:\n",
    "              break\n",
    "            s_i, n_s_i, a_i, r_i, game_over_i = batch[i]\n",
    "            #print(\"a_i\",a_i)\n",
    "            #print(\"game_\",game_over_i.shape)\n",
    "            #print(\"r_i\",r_i.shape)\n",
    "            input_states[i] = s_i \n",
    "            #default\n",
    "            target_q[i] = self.model.predict(s_i[np.newaxis,:,:,:])\n",
    "            \n",
    "            if game_over_i:\n",
    "                target_q[i,a_i] = r_i\n",
    "            else:\n",
    "                target_q[i,a_i] = r_i + self.discount * np.max(self.model.predict(s_i[np.newaxis,:,:,:]))\n",
    "        #print(\"input_shape\",input_states.shape)\n",
    "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "\n",
    "        return l\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=(5,5,2)))\n",
    "        model.add(Dense(100))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(30))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(4))\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63813,
     "status": "error",
     "timestamp": 1579643321213,
     "user": {
      "displayName": "Léo Andéol",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCZ9lXKogam3N-Zp1ZulY_dPre1MZo_DYuijwWz=s64",
      "userId": "15347828844155644240"
     },
     "user_tz": -60
    },
    "id": "eTbKQvAnyh3A",
    "outputId": "cba7d031-1345-4664-d75e-0d3a8881adb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leo/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/leo/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 000/051 | Loss 0.0091 | Win/lose count 3.5/7.0 (-3.5)\n",
      "Epoch 001/051 | Loss 0.0068 | Win/lose count 3.0/5.0 (-2.0)\n",
      "Epoch 002/051 | Loss 0.0161 | Win/lose count 3.5/8.0 (-4.5)\n",
      "Epoch 003/051 | Loss 0.0066 | Win/lose count 8.0/7.0 (1.0)\n",
      "Epoch 004/051 | Loss 0.0035 | Win/lose count 4.5/4.0 (0.5)\n",
      "Epoch 005/051 | Loss 0.0097 | Win/lose count 7.0/2.0 (5.0)\n",
      "Epoch 006/051 | Loss 0.0035 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 007/051 | Loss 0.0022 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 008/051 | Loss 0.0030 | Win/lose count 5.5/7.0 (-1.5)\n",
      "Epoch 009/051 | Loss 0.0024 | Win/lose count 7.0/7.0 (0.0)\n",
      "Epoch 010/051 | Loss 0.0032 | Win/lose count 6.0/4.0 (2.0)\n",
      "Epoch 011/051 | Loss 0.0096 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 012/051 | Loss 0.0113 | Win/lose count 6.5/0 (6.5)\n",
      "Epoch 013/051 | Loss 0.0076 | Win/lose count 5.0/2.0 (3.0)\n",
      "Epoch 014/051 | Loss 0.0020 | Win/lose count 7.0/5.0 (2.0)\n",
      "Epoch 015/051 | Loss 0.0054 | Win/lose count 3.5/1.0 (2.5)\n",
      "Epoch 016/051 | Loss 0.0260 | Win/lose count 5.0/2.0 (3.0)\n",
      "Epoch 017/051 | Loss 0.0080 | Win/lose count 4.5/0 (4.5)\n",
      "Epoch 018/051 | Loss 0.0011 | Win/lose count 3.5/3.0 (0.5)\n",
      "Epoch 019/051 | Loss 0.0032 | Win/lose count 5.5/8.0 (-2.5)\n",
      "Epoch 020/051 | Loss 0.0008 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 021/051 | Loss 0.0071 | Win/lose count 5.5/0 (5.5)\n",
      "Epoch 022/051 | Loss 0.0008 | Win/lose count 6.0/1.0 (5.0)\n",
      "Epoch 023/051 | Loss 0.0034 | Win/lose count 6.5/3.0 (3.5)\n",
      "Epoch 024/051 | Loss 0.0018 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 025/051 | Loss 0.0011 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 026/051 | Loss 0.0041 | Win/lose count 8.5/4.0 (4.5)\n",
      "Epoch 027/051 | Loss 0.0024 | Win/lose count 10.0/2.0 (8.0)\n",
      "Epoch 028/051 | Loss 0.0046 | Win/lose count 3.0/5.0 (-2.0)\n",
      "Epoch 029/051 | Loss 0.0033 | Win/lose count 5.0/1.0 (4.0)\n",
      "Epoch 030/051 | Loss 0.0034 | Win/lose count 12.0/3.0 (9.0)\n",
      "Epoch 031/051 | Loss 0.0066 | Win/lose count 3.0/0 (3.0)\n",
      "Epoch 032/051 | Loss 0.0064 | Win/lose count 13.0/8.0 (5.0)\n",
      "Epoch 033/051 | Loss 0.0014 | Win/lose count 5.5/1.0 (4.5)\n",
      "Epoch 034/051 | Loss 0.0026 | Win/lose count 10.0/3.0 (7.0)\n",
      "Epoch 035/051 | Loss 0.0019 | Win/lose count 16.5/3.0 (13.5)\n",
      "Epoch 036/051 | Loss 0.0020 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 037/051 | Loss 0.0050 | Win/lose count 14.0/1.0 (13.0)\n",
      "Epoch 038/051 | Loss 0.0056 | Win/lose count 14.5/1.0 (13.5)\n",
      "Epoch 039/051 | Loss 0.0033 | Win/lose count 7.0/4.0 (3.0)\n",
      "Epoch 040/051 | Loss 0.0020 | Win/lose count 9.0/5.0 (4.0)\n",
      "Epoch 041/051 | Loss 0.0051 | Win/lose count 19.5/6.0 (13.5)\n",
      "Epoch 042/051 | Loss 0.0011 | Win/lose count 11.0/3.0 (8.0)\n",
      "Epoch 043/051 | Loss 0.0012 | Win/lose count 12.0/4.0 (8.0)\n",
      "Epoch 044/051 | Loss 0.0023 | Win/lose count 12.0/3.0 (9.0)\n",
      "Epoch 045/051 | Loss 0.0024 | Win/lose count 5.0/1.0 (4.0)\n",
      "Epoch 046/051 | Loss 0.0047 | Win/lose count 10.0/2.0 (8.0)\n",
      "Epoch 047/051 | Loss 0.0045 | Win/lose count 6.5/3.0 (3.5)\n",
      "Epoch 048/051 | Loss 0.0045 | Win/lose count 11.0/1.0 (10.0)\n",
      "Epoch 049/051 | Loss 0.0013 | Win/lose count 13.0/2.0 (11.0)\n",
      "Epoch 050/051 | Loss 0.0031 | Win/lose count 1.5/4.0 (-2.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent, env, epochs_train, prefix='fc_train')\n",
    "HTML(display_videos('fc_train50.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vmgk3JnYyh3E"
   },
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBbeomzMyh3F"
   },
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filters=30,kernel_size=3,input_shape=(5,5,self.n_state)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(filters=20,kernel_size=3))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4))\n",
    "        \n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 377538,
     "status": "error",
     "timestamp": 1579645042154,
     "user": {
      "displayName": "Léo Andéol",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCZ9lXKogam3N-Zp1ZulY_dPre1MZo_DYuijwWz=s64",
      "userId": "15347828844155644240"
     },
     "user_tz": -60
    },
    "id": "zibomlQgyh3N",
    "outputId": "f695ec61-c1af-4fa6-8946-9948927e334a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/051 | Loss 0.0056 | Win/lose count 4.0/2.0 (2.0)\n",
      "Epoch 001/051 | Loss 0.0085 | Win/lose count 2.0/7.0 (-5.0)\n",
      "Epoch 002/051 | Loss 0.0019 | Win/lose count 3.0/6.0 (-3.0)\n",
      "Epoch 003/051 | Loss 0.0026 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 004/051 | Loss 0.0001 | Win/lose count 5.0/3.0 (2.0)\n",
      "Epoch 005/051 | Loss 0.0000 | Win/lose count 2.0/5.0 (-3.0)\n",
      "Epoch 006/051 | Loss 0.0102 | Win/lose count 1.0/4.0 (-3.0)\n",
      "Epoch 007/051 | Loss 0.0161 | Win/lose count 2.5/3.0 (-0.5)\n",
      "Epoch 008/051 | Loss 0.0021 | Win/lose count 1.5/6.0 (-4.5)\n",
      "Epoch 009/051 | Loss 0.0203 | Win/lose count 2.0/7.0 (-5.0)\n",
      "Epoch 010/051 | Loss 0.0176 | Win/lose count 3.0/5.0 (-2.0)\n",
      "Epoch 011/051 | Loss 0.0074 | Win/lose count 4.0/5.0 (-1.0)\n",
      "Epoch 012/051 | Loss 0.0039 | Win/lose count 6.5/4.0 (2.5)\n",
      "Epoch 013/051 | Loss 0.0049 | Win/lose count 4.5/4.0 (0.5)\n",
      "Epoch 014/051 | Loss 0.0081 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 015/051 | Loss 0.0168 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 016/051 | Loss 0.0021 | Win/lose count 4.5/4.0 (0.5)\n",
      "Epoch 017/051 | Loss 0.0081 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 018/051 | Loss 0.0098 | Win/lose count 2.5/0 (2.5)\n",
      "Epoch 019/051 | Loss 0.0032 | Win/lose count 2.5/3.0 (-0.5)\n",
      "Epoch 020/051 | Loss 0.0075 | Win/lose count 4.5/6.0 (-1.5)\n",
      "Epoch 021/051 | Loss 0.0129 | Win/lose count 8.5/8.0 (0.5)\n",
      "Epoch 022/051 | Loss 0.0077 | Win/lose count 1.0/3.0 (-2.0)\n",
      "Epoch 023/051 | Loss 0.0049 | Win/lose count 3.0/4.0 (-1.0)\n",
      "Epoch 024/051 | Loss 0.0041 | Win/lose count 3.5/5.0 (-1.5)\n",
      "Epoch 025/051 | Loss 0.0060 | Win/lose count 1.5/0 (1.5)\n",
      "Epoch 026/051 | Loss 0.0044 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 027/051 | Loss 0.0023 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 028/051 | Loss 0.0079 | Win/lose count 1.5/3.0 (-1.5)\n",
      "Epoch 029/051 | Loss 0.0000 | Win/lose count 3.5/4.0 (-0.5)\n",
      "Epoch 030/051 | Loss 0.0086 | Win/lose count 4.0/5.0 (-1.0)\n",
      "Epoch 031/051 | Loss 0.0071 | Win/lose count 1.0/4.0 (-3.0)\n",
      "Epoch 032/051 | Loss 0.0208 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 033/051 | Loss 0.0113 | Win/lose count 4.5/4.0 (0.5)\n",
      "Epoch 034/051 | Loss 0.0016 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 035/051 | Loss 0.0020 | Win/lose count 2.0/0 (2.0)\n",
      "Epoch 036/051 | Loss 0.0076 | Win/lose count 7.0/2.0 (5.0)\n",
      "Epoch 037/051 | Loss 0.0165 | Win/lose count 6.5/5.0 (1.5)\n",
      "Epoch 038/051 | Loss 0.0097 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 039/051 | Loss 0.0144 | Win/lose count 1.5/2.0 (-0.5)\n",
      "Epoch 040/051 | Loss 0.0044 | Win/lose count 0.5/0 (0.5)\n",
      "Epoch 041/051 | Loss 0.0028 | Win/lose count 3.0/6.0 (-3.0)\n",
      "Epoch 042/051 | Loss 0.0002 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 043/051 | Loss 0.0001 | Win/lose count 5.0/3.0 (2.0)\n",
      "Epoch 044/051 | Loss 0.0020 | Win/lose count 5.0/1.0 (4.0)\n",
      "Epoch 045/051 | Loss 0.0019 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 046/051 | Loss 0.0124 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 047/051 | Loss 0.0053 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 048/051 | Loss 0.0041 | Win/lose count 4.5/2.0 (2.5)\n",
      "Epoch 049/051 | Loss 0.0068 | Win/lose count 6.5/8.0 (-1.5)\n",
      "Epoch 050/051 | Loss 0.0020 | Win/lose count 7.5/2.0 (5.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.01, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent,env,epochs_train,prefix='cnn_train')\n",
    "HTML(display_videos('cnn_train50.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eujJaMGyh3Q"
   },
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13rs9poPyh3Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of the CNN\n",
      "Win/lose count 27.5/1.0. Average score (26.5)\n",
      "Win/lose count 22.0/3.0. Average score (22.75)\n",
      "Win/lose count 28.5/4.0. Average score (23.333333333333332)\n",
      "Win/lose count 12.0/4.0. Average score (19.5)\n",
      "Win/lose count 36.5/3.0. Average score (22.3)\n",
      "Win/lose count 22.5/2.0. Average score (22.0)\n",
      "Win/lose count 12.5/1.0. Average score (20.5)\n",
      "Win/lose count 14.5/5.0. Average score (19.125)\n",
      "Win/lose count 5.0/1.0. Average score (17.444444444444443)\n",
      "Win/lose count 34.5/5.0. Average score (18.65)\n",
      "Win/lose count 8.0/1.0. Average score (17.59090909090909)\n",
      "Final score: 17.59090909090909\n",
      "Test of the FC\n",
      "Win/lose count 5.0/0. Average score (5.0)\n",
      "Win/lose count 9.0/3.0. Average score (5.5)\n",
      "Win/lose count 3.5/1.0. Average score (4.5)\n",
      "Win/lose count 4.0/0. Average score (4.375)\n",
      "Win/lose count 2.5/1.0. Average score (3.8)\n",
      "Win/lose count 3.5/1.0. Average score (3.5833333333333335)\n",
      "Win/lose count 10.5/2.0. Average score (4.285714285714286)\n",
      "Win/lose count 3.5/0. Average score (4.1875)\n",
      "Win/lose count 10.0/2.0. Average score (4.611111111111111)\n",
      "Win/lose count 12.0/5.0. Average score (4.85)\n",
      "Win/lose count 20.5/6.0. Average score (5.7272727272727275)\n",
      "Final score: 5.7272727272727275\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T,temperature=0.8)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAikup5fyh3U"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0k8CSazyh3X"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PgyaBG4Fyh3e"
   },
   "source": [
    "The issue is that the agent does not explore and generally stays very close to its starting point, since it does not remember where it has already been, it turns around. When the temperature is high, and the starting location not too bad, it explores well due to being surrounded by bonuses. But when temperature is lower and bonuses sparser, it does only clear the area around its starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T6wCcXjXyh3f"
   },
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MmW4dpUIyh3h"
   },
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        agent.set_epsilon(agent.epsilon*0.9)\n",
    "        print(\"New Epsilon = \",agent.epsilon)\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "        \n",
    "class EnvironmentExploring(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "        self.malus_position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:,-2:] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        #reward = self.board[self.x, self.y]\n",
    "        game_over = self.t > self.max_time\n",
    "        reward = 0\n",
    "        if train:\n",
    "            reward = -self.malus_position[self.x, self.y]\n",
    "        self.malus_position[self.x, self.y] = 0.1\n",
    "\n",
    "        reward = reward + self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        # 3 \"feature\" states instead of 2\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[:,-2:] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "        #reset also the malus\n",
    "        self.malus_position = np.zeros((self.grid_size,self.grid_size))\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XeMqtF3cyh3l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Epsilon =  0.81\n",
      "Epoch 000/051 | Loss 0.0200 | Win/lose count 12.5/33.60000000000012 (-21.100000000000122)\n",
      "New Epsilon =  0.7290000000000001\n",
      "Epoch 001/051 | Loss 0.0136 | Win/lose count 12.0/24.00000000000007 (-12.000000000000071)\n",
      "New Epsilon =  0.6561000000000001\n",
      "Epoch 002/051 | Loss 0.0049 | Win/lose count 10.5/24.400000000000087 (-13.900000000000087)\n",
      "New Epsilon =  0.5904900000000002\n",
      "Epoch 003/051 | Loss 0.0161 | Win/lose count 9.0/24.600000000000048 (-15.600000000000048)\n",
      "New Epsilon =  0.5314410000000002\n",
      "Epoch 004/051 | Loss 0.0090 | Win/lose count 19.5/20.100000000000023 (-0.6000000000000227)\n",
      "New Epsilon =  0.47829690000000014\n",
      "Epoch 005/051 | Loss 0.0032 | Win/lose count 12.0/23.700000000000088 (-11.700000000000088)\n",
      "New Epsilon =  0.43046721000000016\n",
      "Epoch 006/051 | Loss 0.0034 | Win/lose count 11.0/24.60000000000002 (-13.60000000000002)\n",
      "New Epsilon =  0.38742048900000015\n",
      "Epoch 007/051 | Loss 0.0326 | Win/lose count 9.0/24.500000000000068 (-15.500000000000068)\n",
      "New Epsilon =  0.34867844010000015\n",
      "Epoch 008/051 | Loss 0.0406 | Win/lose count 15.5/18.1 (-2.6000000000000014)\n",
      "New Epsilon =  0.31381059609000017\n",
      "Epoch 009/051 | Loss 0.0078 | Win/lose count 17.0/18.400000000000006 (-1.4000000000000057)\n",
      "New Epsilon =  0.28242953648100017\n",
      "Epoch 010/051 | Loss 0.0399 | Win/lose count 21.5/16.09999999999997 (5.4000000000000306)\n",
      "New Epsilon =  0.25418658283290013\n",
      "Epoch 011/051 | Loss 0.0057 | Win/lose count 13.0/20.400000000000034 (-7.400000000000034)\n",
      "New Epsilon =  0.22876792454961012\n",
      "Epoch 012/051 | Loss 0.0069 | Win/lose count 23.5/16.299999999999976 (7.200000000000024)\n",
      "New Epsilon =  0.2058911320946491\n",
      "Epoch 013/051 | Loss 0.0124 | Win/lose count 15.0/21.40000000000002 (-6.40000000000002)\n",
      "New Epsilon =  0.1853020188851842\n",
      "Epoch 014/051 | Loss 0.0241 | Win/lose count 11.0/23.400000000000016 (-12.400000000000016)\n",
      "New Epsilon =  0.16677181699666577\n",
      "Epoch 015/051 | Loss 0.0092 | Win/lose count 19.0/17.8 (1.1999999999999993)\n",
      "New Epsilon =  0.1500946352969992\n",
      "Epoch 016/051 | Loss 0.0102 | Win/lose count 19.5/16.699999999999974 (2.8000000000000256)\n",
      "New Epsilon =  0.13508517176729928\n",
      "Epoch 017/051 | Loss 0.0070 | Win/lose count 13.5/20.900000000000027 (-7.400000000000027)\n",
      "New Epsilon =  0.12157665459056936\n",
      "Epoch 018/051 | Loss 0.0188 | Win/lose count 18.0/13.799999999999974 (4.200000000000026)\n",
      "New Epsilon =  0.10941898913151243\n",
      "Epoch 019/051 | Loss 0.0049 | Win/lose count 23.5/14.69999999999997 (8.80000000000003)\n",
      "New Epsilon =  0.0984770902183612\n",
      "Epoch 020/051 | Loss 0.0022 | Win/lose count 19.0/14.499999999999972 (4.500000000000028)\n",
      "New Epsilon =  0.08862938119652508\n",
      "Epoch 021/051 | Loss 0.0171 | Win/lose count 15.0/14.199999999999966 (0.8000000000000345)\n",
      "New Epsilon =  0.07976644307687257\n",
      "Epoch 022/051 | Loss 0.0030 | Win/lose count 11.5/19.099999999999987 (-7.599999999999987)\n",
      "New Epsilon =  0.07178979876918531\n",
      "Epoch 023/051 | Loss 0.0129 | Win/lose count 22.0/15.199999999999967 (6.800000000000033)\n",
      "New Epsilon =  0.06461081889226679\n",
      "Epoch 024/051 | Loss 0.0053 | Win/lose count 16.0/15.299999999999969 (0.7000000000000313)\n",
      "New Epsilon =  0.05814973700304011\n",
      "Epoch 025/051 | Loss 0.0045 | Win/lose count 19.0/15.099999999999973 (3.900000000000027)\n",
      "New Epsilon =  0.0523347633027361\n",
      "Epoch 026/051 | Loss 0.0212 | Win/lose count 19.0/15.999999999999963 (3.0000000000000373)\n",
      "New Epsilon =  0.04710128697246249\n",
      "Epoch 027/051 | Loss 0.0079 | Win/lose count 18.0/14.299999999999974 (3.700000000000026)\n",
      "New Epsilon =  0.042391158275216244\n",
      "Epoch 028/051 | Loss 0.0073 | Win/lose count 10.0/18.199999999999978 (-8.199999999999978)\n",
      "New Epsilon =  0.03815204244769462\n",
      "Epoch 029/051 | Loss 0.0075 | Win/lose count 16.0/15.599999999999968 (0.40000000000003233)\n",
      "New Epsilon =  0.03433683820292516\n",
      "Epoch 030/051 | Loss 0.0097 | Win/lose count 14.0/13.899999999999967 (0.1000000000000334)\n",
      "New Epsilon =  0.030903154382632643\n",
      "Epoch 031/051 | Loss 0.0160 | Win/lose count 20.0/13.799999999999967 (6.200000000000033)\n",
      "New Epsilon =  0.02781283894436938\n",
      "Epoch 032/051 | Loss 0.0063 | Win/lose count 17.5/13.999999999999977 (3.500000000000023)\n",
      "New Epsilon =  0.025031555049932444\n",
      "Epoch 033/051 | Loss 0.0099 | Win/lose count 8.0/18.299999999999994 (-10.299999999999994)\n",
      "New Epsilon =  0.0225283995449392\n",
      "Epoch 034/051 | Loss 0.0058 | Win/lose count 15.0/16.39999999999997 (-1.3999999999999702)\n",
      "New Epsilon =  0.020275559590445278\n",
      "Epoch 035/051 | Loss 0.0062 | Win/lose count 19.5/12.599999999999975 (6.900000000000025)\n",
      "New Epsilon =  0.01824800363140075\n",
      "Epoch 036/051 | Loss 0.0094 | Win/lose count 5.0/18.39999999999999 (-13.399999999999991)\n",
      "New Epsilon =  0.016423203268260675\n",
      "Epoch 037/051 | Loss 0.0021 | Win/lose count 13.5/17.099999999999977 (-3.5999999999999766)\n",
      "New Epsilon =  0.014780882941434608\n",
      "Epoch 038/051 | Loss 0.0065 | Win/lose count 15.0/14.499999999999968 (0.500000000000032)\n",
      "New Epsilon =  0.013302794647291147\n",
      "Epoch 039/051 | Loss 0.0134 | Win/lose count 7.0/17.799999999999983 (-10.799999999999983)\n",
      "New Epsilon =  0.011972515182562033\n",
      "Epoch 040/051 | Loss 0.0078 | Win/lose count 24.5/12.599999999999978 (11.900000000000022)\n",
      "New Epsilon =  0.01077526366430583\n",
      "Epoch 041/051 | Loss 0.0037 | Win/lose count 20.5/13.199999999999973 (7.300000000000027)\n",
      "New Epsilon =  0.009697737297875247\n",
      "Epoch 042/051 | Loss 0.0308 | Win/lose count 21.0/15.199999999999969 (5.800000000000031)\n",
      "New Epsilon =  0.008727963568087723\n",
      "Epoch 043/051 | Loss 0.0042 | Win/lose count 10.0/17.29999999999998 (-7.299999999999979)\n",
      "New Epsilon =  0.00785516721127895\n",
      "Epoch 044/051 | Loss 0.0064 | Win/lose count 11.5/17.599999999999984 (-6.099999999999984)\n",
      "New Epsilon =  0.007069650490151055\n",
      "Epoch 045/051 | Loss 0.0080 | Win/lose count 26.5/12.799999999999978 (13.700000000000022)\n",
      "New Epsilon =  0.00636268544113595\n",
      "Epoch 046/051 | Loss 0.0060 | Win/lose count 15.5/15.099999999999968 (0.40000000000003233)\n",
      "New Epsilon =  0.005726416897022355\n",
      "Epoch 047/051 | Loss 0.0019 | Win/lose count 12.5/15.199999999999962 (-2.699999999999962)\n",
      "New Epsilon =  0.00515377520732012\n",
      "Epoch 048/051 | Loss 0.0171 | Win/lose count 10.5/16.99999999999997 (-6.499999999999972)\n",
      "New Epsilon =  0.004638397686588107\n",
      "Epoch 049/051 | Loss 0.0015 | Win/lose count 20.0/14.599999999999971 (5.400000000000029)\n",
      "New Epsilon =  0.0041745579179292966\n",
      "Epoch 050/051 | Loss 0.0068 | Win/lose count 5.5/16.599999999999966 (-11.099999999999966)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.9, memory_size=2000, batch_size = 32,n_state=3)\n",
    "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
    "HTML(display_videos('cnn_train_explore50.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NfkkNku9yh3o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 1.5/19.0. Average score (-17.5)\n",
      "Win/lose count 7.0/17.69999999999998. Average score (-14.09999999999999)\n",
      "Win/lose count 7.5/17.799999999999983. Average score (-12.833333333333321)\n",
      "Win/lose count 9.0/16.399999999999963. Average score (-11.474999999999982)\n",
      "Win/lose count 11.5/16.19999999999996. Average score (-10.119999999999978)\n",
      "Win/lose count 11.5/15.199999999999962. Average score (-9.049999999999974)\n",
      "Win/lose count 17.0/15.099999999999962. Average score (-7.485714285714258)\n",
      "Win/lose count 4.0/18.099999999999987. Average score (-8.312499999999975)\n",
      "Win/lose count 5.5/18.29999999999999. Average score (-8.811111111111087)\n",
      "Win/lose count 13.5/14.199999999999966. Average score (-7.999999999999974)\n",
      "Win/lose count 9.0/17.69999999999998. Average score (-8.06363636363634)\n",
      "Final score: -8.06363636363634\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NUMAF-Cfyh3s"
   },
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xJFYUm-Fyh3t"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZOnNqVfxyh3t"
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DQN_project_MVA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
